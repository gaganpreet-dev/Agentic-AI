{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e8264a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87e6aaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac8faa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276e0f1",
   "metadata": {},
   "source": [
    "Example 1: Simple LLM Call With Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d564530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a20504cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x000001A00D014690>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001A00D015090>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b091bfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "response = llm.invoke(\"What is the capital of France?\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba9b81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Messages\n",
    "\n",
    "messages=[\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What are the 2 benefits of LangChain?\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70cf5957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"LangChain is an open-source Python framework that provides a set of tools for building large language models (LLMs) and conversational AI systems. Two benefits of LangChain include:\\n\\n1. **Ease of Use**: LangChain simplifies the process of developing and integrating large language models into various applications, making it easier for developers to create complex conversational interfaces.\\n\\n2. **Modularity and Extensibility**: LangChain's modular design allows developers to easily integrate different LLMs, data sources, and other components to build custom conversational AI systems. This extensibility makes it easier to adapt to changing requirements and integrate new technologies.\\n\\nIf you'd like to know more about LangChain or its benefits, please let me know.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 148, 'prompt_tokens': 51, 'total_tokens': 199, 'completion_time': 0.344894433, 'completion_tokens_details': None, 'prompt_time': 0.002558319, 'prompt_tokens_details': None, 'queue_time': 0.046362951, 'total_time': 0.347452752}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c6b90-4d70-7fd1-99e2-4dc817d1e2c9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 51, 'output_tokens': 148, 'total_tokens': 199})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Invoke the model\n",
    "\n",
    "response=model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b228e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
